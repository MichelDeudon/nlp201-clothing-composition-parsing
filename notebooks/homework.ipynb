{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carbonfact - Named Entity Recognition & Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author Michel DEUDON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(\"../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloader import fetch_data\n",
    "inputs, targets, materials = fetch_data()\n",
    "assert len(inputs) == len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size=0.1, random_state=42)\n",
    "print(\"Collected {} training examples and {} testing examples\".format(len(inputs_train), len(inputs_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INPUT \", inputs_train[0])\n",
    "print(\"LABEL \", targets_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Clothing components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components = np.sort(list(set([v for u in targets_train for v in list(u.keys()) if v!=''])))\n",
    "all_components[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Clothing materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_materials = np.sort([w for w in list(set(materials)) if w!=''])\n",
    "all_materials[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\" Abbreviate text (reduce dimensionality, keep info), e.g., Polyamide --> plymd \"\"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    for c in text:\n",
    "        if c not in ' %0123456789&:;,-bcdfghklmnpqrstvwxy': # keep non vowels (except y)\n",
    "            text = text.replace(c, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify preprocessing no collisions\n",
    "assert len(all_components) == len(set([preprocess(u) for u in all_components]))\n",
    "assert len(all_materials) == len(set([preprocess(u) for u in all_materials]))\n",
    "assert len(all_components)+len(all_materials) == len(set([preprocess(u) for u in all_components]+[preprocess(u) for u in all_materials]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess all_materials and components\n",
    "all_materials_p = [preprocess(w) for w in all_materials]\n",
    "all_components_p = [preprocess(w.replace(\"_\", \" \")) for w in all_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from low to high dimension\n",
    "reverse_mapping_materials = dict(zip(all_materials_p, all_materials))\n",
    "reverse_mapping_components = dict(zip(all_components_p, all_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL   \", inputs_train[4])\n",
    "print(\"ABBREVIATED\", preprocess(inputs_train[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Initialize/fit HMM model prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Hidden states transitions' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli or Gaussian HMM with 4 hidden states\n",
    "states = [\"component\", \"material\", \"proportion\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_start_probs_trans_mat(targets, eps = 0.0001):\n",
    "    ''' Markov Chain start_probs (n_hidden) and transition probability matrix (n_hidden, n_hidden) '''\n",
    "    \n",
    "    start_probs = np.zeros(4) # component, material, proportion, other\n",
    "    trans_mat = np.zeros((4,4)) # transition probabilities between hidden state\n",
    "\n",
    "    for t in targets:\n",
    "        for k,v in t.items():\n",
    "\n",
    "            # inspect components k\n",
    "            if k==\"\" and len(t.keys())==1:\n",
    "                start_probs[2] +=1 # start with proportion\n",
    "            else:\n",
    "                start_probs[0] +=1 # start with component\n",
    "                trans_mat[0][0] +=len(k) # len of component (ex: lace)\n",
    "                trans_mat[0][1] += 0.3\n",
    "                trans_mat[0][2] += 0.3\n",
    "                trans_mat[0][3] += 0.3\n",
    "\n",
    "            # inspect proportions / materials\n",
    "            for w in v:\n",
    "                trans_mat[1][1] += len(w[\"material\"]) # len of material (ex: nylon)\n",
    "                trans_mat[1][0] += 1\n",
    "                trans_mat[1][2] += 1\n",
    "                trans_mat[1][3] += 1\n",
    "\n",
    "                trans_mat[2][2] += 3 # len of proportions (ex: 80%)\n",
    "                trans_mat[2][0] += 0.3\n",
    "                trans_mat[2][1] += 0.3\n",
    "                trans_mat[2][3] += 0.3\n",
    "    \n",
    "    # TODO smooth & normalize probabilities\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    return start_probs, trans_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Emission model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.sort(list(set([c for s in inputs for c in preprocess(s)])))\n",
    "charlist = \"\".join(alphabet) # All observed emissions\n",
    "charlist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(lexic, eps=0.0001):\n",
    "    \"\"\" Calculate emission probs (character statistics) from lexic (list of keywords)\"\"\"\n",
    "    \n",
    "    alphabet, counts = np.unique([c for w in lexic for c in w], return_counts=True)\n",
    "    v = np.zeros(len(charlist))\n",
    "    for i,c in enumerate(charlist):\n",
    "        if c in alphabet:\n",
    "            idx, = np.where(alphabet==c)\n",
    "            v[i] = counts[idx[0]]\n",
    "\n",
    "    v = v + eps\n",
    "    v = v / v.sum()\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_emission_probs(eps = 0.0001):\n",
    "    ''' Emission probability matrix (n_hidden, n_observed) '''\n",
    "    \n",
    "    emission_probs = np.zeros((len(states),len(charlist)))\n",
    "\n",
    "    # set state emissions from observations\n",
    "    emission_probs[0] = vectorize(lexic=all_components) # component char emissions\n",
    "    emission_probs[1] = vectorize(lexic=all_materials) # material char emissions\n",
    "    emission_probs[2] = vectorize(lexic=[\"0123456789% \"]) # proportion\n",
    "    emission_probs[3] = vectorize(lexic=[\"-&,:; \"]) # other\n",
    "    \n",
    "    # TODO smooth & normalize probabilities\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    return emission_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_probs, trans_mat = init_start_probs_trans_mat(targets_train)\n",
    "emission_probs = init_emission_probs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.hmm import plot_parameters\n",
    "#plot_parameters(states, trans_mat, emission_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract entities from hidden states (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Given a string, extract its components, materials, proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence, states, emission_probs, trans_mat):\n",
    "    '''\n",
    "    Viterbi implementation of maximum a posteriori optimization for HMM model using dynamic programming.\n",
    "    Returns most likely sequence of hidden states.\n",
    "    Args:\n",
    "        sentence: List[int], list of character id\n",
    "        states: List[str], list of hidden states names\n",
    "        emissions_probs: np.array, emission matrix (n_hidden, n_observed)\n",
    "        trans_mat: np.array, transition matrix (n_hidden, n_hidden)\n",
    "    Returns:\n",
    "        sequence: List[int], list of hidden states id\n",
    "    '''\n",
    "    \n",
    "    # TODO complete the viterbi algorithm\n",
    "    \n",
    "    sequence = np.zeros(len(sentence))\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id = dict(zip(charlist,np.arange(len(charlist))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(text):\n",
    "    ''' Extract entities from text with HMM and maximum a posteriori (Viterbi algorithm) '''\n",
    "    \n",
    "    ps = preprocess(text)\n",
    "    obs = [char2id[c] for c in ps]\n",
    "    #print(text)\n",
    "    #print(ps)\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    all_position = []\n",
    "    labels = OrderedDict()\n",
    "\n",
    "    hidden_seq = viterbi(obs, states, emission_probs, trans_mat) # predict hidden states sequence\n",
    "    hidden_seq = np.array(hidden_seq)\n",
    "    for s in states:\n",
    "        positions, = np.where(hidden_seq==s)\n",
    "        diff = positions[1:]-positions[:-1]\n",
    "        positions = [p for i,p in enumerate(positions) if i==0 or diff[i-1]>1]\n",
    "        n = len(positions) # number of instances of state in text\n",
    "        if n > 0:\n",
    "            for p in positions:\n",
    "                labels[p] = s\n",
    "            all_position += positions\n",
    "\n",
    "\n",
    "    breaks = np.sort(all_position)\n",
    "    result = []\n",
    "    for i in range(len(breaks)-1):\n",
    "        start,stop = breaks[i],breaks[i+1]\n",
    "        if labels[start] != 'other':\n",
    "            result.append( (ps[start:stop],labels[start],start,stop) )\n",
    "    \n",
    "    if len(breaks)>0:\n",
    "        result.append( (ps[stop:],labels[stop],stop,len(ps)) )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_NER(result):\n",
    "    ''' Ensure NER in all_components or all_materials '''\n",
    "    \n",
    "    new_result = []\n",
    "    for u in result:\n",
    "        substring = u[0].strip()\n",
    "        if substring in all_components_p:\n",
    "            new_result.append((substring, \"component\"))\n",
    "        elif substring in all_materials_p:\n",
    "            new_result.append((substring, \"material\"))\n",
    "        else:\n",
    "            new_result.append((substring, u[1]))\n",
    "    return new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = NER(inputs_train[0])\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_result = clean_NER(result)\n",
    "#new_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extract relationships from entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2f(x):\n",
    "    ''' Utility: Percentage to float (for proportions)'''\n",
    "    try:\n",
    "        return float(x.strip('%'))\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations(text):\n",
    "    \"\"\" Extract relations: clothe <> component <> materials <> proportion \"\"\"\n",
    "    \n",
    "    entities = NER(text)\n",
    "    entities = clean_NER(entities)\n",
    "\n",
    "    relation = {}\n",
    "    last_component = \"\"\n",
    "    current_part = {'material': \"\", 'proportion': 0.0}\n",
    "    flag = False\n",
    "    for text, label in entities:\n",
    "        if label == \"component\":\n",
    "            if text in reverse_mapping_components:\n",
    "                last_component = reverse_mapping_components[text]\n",
    "            else:\n",
    "                last_component = text\n",
    "                flag = True # warning component not recognized\n",
    "        elif label == \"material\":\n",
    "            if text in reverse_mapping_materials:\n",
    "                current_part[\"material\"] = reverse_mapping_materials[text]\n",
    "            else:\n",
    "                current_part[\"material\"] = text \n",
    "                flag = True # warning material not recognized\n",
    "        elif label == \"proportion\":\n",
    "            current_part[\"proportion\"] = p2f(text)\n",
    "\n",
    "        if current_part[\"material\"] != \"\" and current_part['proportion'] != 0.0:\n",
    "            if last_component not in relation:\n",
    "                relation[last_component] = []\n",
    "            relation[last_component].append(current_part)\n",
    "            current_part = {'material': \"\", 'proportion': 0.0}\n",
    "            \n",
    "    return relation, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 10\n",
    "#text = inputs_train[i]\n",
    "#label = targets_train[i]\n",
    "#relation, flag = extract_relations(text)\n",
    "\n",
    "#print(text)\n",
    "#print(\"Warning:\", flag)\n",
    "#print(\"Assert:\", label == relation, '\\n')\n",
    "\n",
    "#print(label, '\\n')\n",
    "#print(relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_model(inputs, targets):\n",
    "    ''' Calculate model accuracy and warnings'''\n",
    "\n",
    "    warnings = 0\n",
    "    accurate = 0\n",
    "    outputs = []\n",
    "    for i in range(len(inputs)):\n",
    "        text = inputs[i]\n",
    "        label = targets[i]\n",
    "        relation, flag = extract_relations(text)\n",
    "        warnings += int(flag)\n",
    "        accurate += int(label == relation)\n",
    "        outputs.append(relation)\n",
    "        \n",
    "        # verify components' compositions sum to 100 (otherwise raise flag, if not already raised)\n",
    "        p_sums = [np.sum([part[\"proportion\"] for part in component]) for component in relation.values()]\n",
    "        if set(p_sums) != set([100.0]) and int(flag) == 0:\n",
    "            warnings += 1\n",
    "    metrics = {\"warnings\": warnings, \"accurate\":accurate}\n",
    "    return outputs, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval model training/testing set (accuracy)\n",
    "outputs_train, metrics_train = score_model(inputs_train, targets_train)\n",
    "outputs_test, metrics_test = score_model(inputs_test, targets_test)\n",
    "print(\"Train accuracy {:.1f}\".format(100*metrics_train[\"accurate\"]/len(inputs_train)))\n",
    "print(\"Test accuracy {:.1f}\".format(100*metrics_test[\"accurate\"]/len(inputs_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval model training/testing set (predicted errors: component/material not recognized or proportions do not sum to 100)\n",
    "print(\"Train warnings {:.1f}\".format(100*metrics_train[\"warnings\"]/len(inputs_train)))\n",
    "print(\"Test warnings {:.1f}\".format(100*metrics_test[\"warnings\"]/len(inputs_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Distributions and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components_distr(output, title=\"\", ylim=12):\n",
    "    lol = [list(row.keys()) for row in output]\n",
    "    distr = np.sort([w for s in lol for w in s if w!=''])\n",
    "    x_labels = np.unique(distr)\n",
    "    plt.hist(distr, color=\"black\")\n",
    "    plt.xticks(np.arange(len(x_labels)), x_labels, rotation=45)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot components distribution (targets vs. outputs on test split)\n",
    "plt.figure(1, figsize=(10, 5))\n",
    "plt.subplot(221)\n",
    "plot_components_distr(targets_test, title=\"Targets components distribution (test)\", ylim=12)\n",
    "plt.subplot(222)\n",
    "plot_components_distr(outputs_test, title=\"Outputs components distribution (test)\", ylim=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components_materials_heatmap(output, title=\"\", vmax=500, eps=0.0000001):\n",
    "    \n",
    "    # convert output to a dictionary components --> materials: proportions (sum)\n",
    "    tmp_dict = {}\n",
    "    for component in all_components:\n",
    "        tmp_dict[component] = {}\n",
    "    for row in output:\n",
    "        for component, composition in row.items():\n",
    "            if component != '' and component in all_components:\n",
    "                for c in composition:\n",
    "                    if c[\"material\"] in all_materials:\n",
    "                        if c[\"material\"] in tmp_dict[component]:\n",
    "                            tmp_dict[component][c[\"material\"]] += c[\"proportion\"]\n",
    "                        else:\n",
    "                            tmp_dict[component][c[\"material\"]] = c[\"proportion\"]\n",
    "                            \n",
    "    # convert dictionary to heatmap\n",
    "    heatmap = np.zeros((len(all_components), len(all_materials)))\n",
    "    for i, c in enumerate(all_components):\n",
    "        for j, m in enumerate(all_materials):\n",
    "            if c in tmp_dict:\n",
    "                if m in tmp_dict[c]:\n",
    "                    heatmap[i][j] = tmp_dict[c][m]\n",
    "                    \n",
    "    # normalize data (each row/components sums to 100)\n",
    "    heatmap = 100*heatmap / (heatmap.sum(axis=1, keepdims=True)+eps)\n",
    "    \n",
    "    # plot heatmap\n",
    "    plt.imshow(heatmap, cmap=\"binary\", vmin=0, vmax=vmax, aspect='auto')\n",
    "    plt.xticks(np.arange(len(all_materials)), all_materials, rotation=90)\n",
    "    plt.yticks(np.arange(len(all_components)), all_components)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot materials per components heatmap\n",
    "plt.figure(1, figsize=(15, 10))\n",
    "plt.subplot(121)\n",
    "plot_components_materials_heatmap(targets_test, title=\"Targets materials per components (test)\", vmax=100)\n",
    "plt.subplot(122)\n",
    "plot_components_materials_heatmap(outputs_test, title=\"Outputs materials per components (test)\", vmax=100)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
